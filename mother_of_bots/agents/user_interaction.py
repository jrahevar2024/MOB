import json
import logging
import os
import asyncio
import time
import uuid
from dotenv import load_dotenv
from langchain_google_vertexai import ChatVertexAI
from agents.requirements_analyzer import analyze_requirements, analyze_and_format_for_code_generation
from agents.code_generation_agent import StandaloneCodeGenerationAgent

# Load environment variables
load_dotenv()

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Vertex AI / Gemini configuration
GCP_PROJECT_ID = os.getenv("GCP_PROJECT_ID", "motherofbots")
GCP_LOCATION = os.getenv("GCP_LOCATION", "us-central1")
GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemini-2.5-flash")

# Removed SPADE UserInteractionAgent - using FastAPI instead

# Standalone User Interaction Agent (no SPADE dependency)
class StandaloneUserInteractionAgent:
    """Standalone version of the agent for use without SPADE/XMPP"""
    
    def __init__(self, name="StandaloneUserInteractionAgent"):
        self.name = name
        self.running = False
        self.message_queue = asyncio.Queue()
        self.direct_responses = {}  # Store responses for direct queries
        self.response_timestamps = {}  # Track when responses were generated
        logger.info(f"Standalone Agent {self.name} initialized")
        
    def _create_system_prompt(self):
        """Create a system prompt for general interactions"""
        return """You are an expert software development assistant specializing in building full-stack web applications.

Your role is to help users:
1. Define and refine their application requirements
2. Suggest best practices for implementation
3. Explain technical concepts clearly
4. Guide them through the development process

When responding:
- Be concise but thorough
- Provide actionable advice
- Use examples when helpful
- Consider both backend (Python/FastAPI) and frontend (React/TailwindCSS) perspectives
- Focus on modern, production-ready solutions

Technical Stack Context:
- Backend: Python, FastAPI, SQLAlchemy (async), Pydantic
- Frontend: React, TailwindCSS, JavaScript
- Database: SQLite (default), PostgreSQL (production)
- API Style: RESTful with proper HTTP status codes"""

    async def generate_response(self, prompt):
        """Generate response using LangChain Vertex AI with Gemini"""
        logger.info(f"Generating response for prompt: {prompt[:30]}...")
        
        try:
            # Use LangChain Vertex AI with Gemini
            logger.info(f"[LangChain] Initializing Gemini via Vertex AI for user interaction (model: {GEMINI_MODEL})")
            llm = ChatVertexAI(
                model=GEMINI_MODEL,
                project=GCP_PROJECT_ID,
                location=GCP_LOCATION,
                temperature=0.3  # Balanced temperature for helpful responses
            )
            
            # Construct full prompt with system context
            system_prompt = self._create_system_prompt()
            full_prompt = f"{system_prompt}\n\n---\n\n{prompt}"
            
            logger.info(f"[LangChain] Invoking response generation via Vertex AI ainvoke()")
            # Invoke asynchronously using LangChain
            response = await llm.ainvoke(full_prompt)
            response_text = response.content if hasattr(response, 'content') else str(response)
            logger.info(f"[LangChain] Response generation completed via Vertex AI ({len(response_text)} chars)")
            return response_text.strip()
        except Exception as e:
            error_msg = f"Error communicating with Vertex AI: {str(e)}"
            logger.error(error_msg)
            return error_msg
    
    async def handle_code_generation_request(self, prompt):
        """Handle a code generation request by analyzing requirements and generating code"""
        logger.info(f"Handling code generation request: {prompt[:30]}...")
        
        try:
            # Step 1: Analyze the requirements
            req_text, req_json = await analyze_and_format_for_code_generation(prompt)
            logger.info(f"Requirements analysis complete: {list(req_json.keys()) if isinstance(req_json, dict) else 'Failed'}")
            
            # Step 2: Generate code using standalone agent
            code_agent = StandaloneCodeGenerationAgent()
            await code_agent.start()
            
            try:
                # Generate code based on requirements
                if isinstance(req_json, dict) and req_json:
                    code = await code_agent.generate_code(req_json)
                else:
                    # Fallback to direct text if JSON parsing failed
                    code = await code_agent.generate_code(prompt)
                
                logger.info(f"Code generation complete: {len(code)} characters")
                
                # Format a nice response with the requirements analysis and the code
                response = f"""## Requirements Analysis
{req_text}

## Generated Code
```python
{code}
```
"""
                return response
                
            finally:
                await code_agent.stop()
                
        except Exception as e:
            error_msg = f"Error during code generation: {str(e)}"
            logger.error(error_msg)
            return error_msg
    
    async def process_messages(self):
        """Process messages from the queue"""
        while self.running:
            try:
                # Get message from queue with timeout
                try:
                    message = await asyncio.wait_for(self.message_queue.get(), timeout=1.0)
                    logger.info(f"Processing message: {message}")
                    
                    # Step 1: Begin processing message
                    logger.info("Step 1: Begin processing user input")
                    
                    # Check if this is a code generation request
                    is_code_request = "generate code" in message["content"].lower() or "create code" in message["content"].lower()
                    
                    if is_code_request:
                        # Handle as a code generation request
                        response = await self.handle_code_generation_request(message["content"])
                    else:
                        # Step 2: Analyze requirements from user input
                        logger.info("Step 2: Analyzing requirements from user input")
                        requirements_analysis = await analyze_requirements(message["content"])
                        logger.info(f"Requirements analysis: {requirements_analysis[:100]}...")
                        
                        # Step 3: Generate response based on analyzed requirements and original input
                        enhanced_prompt = f"""## User Request
{message["content"]}

## Analyzed Requirements
{requirements_analysis}

## Your Task
Based on the user's request and the analyzed requirements above, provide a helpful and actionable response.

Consider:
1. What specific information or guidance does the user need?
2. Are there any clarifying questions you should ask?
3. Can you provide concrete next steps or recommendations?
4. If discussing implementation, reference the appropriate tech stack (FastAPI backend, React frontend)

Provide a clear, well-structured response that directly addresses the user's needs."""
                        
                        # Generate response with enhanced prompt
                        response = await self.generate_response(enhanced_prompt)
                    
                    # Store response for direct queries
                    self.direct_responses[message["id"]] = response
                    self.response_timestamps[message["id"]] = time.time()
                    
                    # Log the response
                    logger.info(f"Generated response: {response[:100]}...")
                    
                    # In a real system, we would send the response back to the sender
                    logger.info(f"Response ready for {message['sender']} (Message ID: {message['id']})")
                    
                    # Mark task as done
                    self.message_queue.task_done()
                except asyncio.TimeoutError:
                    # No message received within timeout
                    pass
                
                # Clean up old responses older than 5 minutes
                current_time = time.time()
                expired_keys = []
                
                for msg_id, timestamp in self.response_timestamps.items():
                    if current_time - timestamp > 300:  # 5 minutes
                        expired_keys.append(msg_id)
                
                for msg_id in expired_keys:
                    if msg_id in self.direct_responses:
                        del self.direct_responses[msg_id]
                    if msg_id in self.response_timestamps:
                        del self.response_timestamps[msg_id]
                
            except Exception as e:
                logger.error(f"Error processing message: {str(e)}")
    
    def add_message(self, sender, content):
        """Add a message to the queue"""
        message_id = f"{sender}_{uuid.uuid4()}"
        self.message_queue.put_nowait({
            "id": message_id,
            "sender": sender,
            "content": content,
            "timestamp": time.time()
        })
        logger.info(f"Message from {sender} added to queue with ID: {message_id}")
        return message_id
    
    async def get_response(self, message_id, timeout=30):
        """Get response for a specific message"""
        start_time = time.time()
        while time.time() - start_time < timeout:
            if message_id in self.direct_responses:
                response = self.direct_responses[message_id]
                # Update timestamp but keep the response
                self.response_timestamps[message_id] = time.time()
                return response
            await asyncio.sleep(0.5)
        return "No response generated in time. Please try again."
        
    async def start(self):
        """Start the agent"""
        logger.info(f"Starting agent {self.name}")
        logger.info(f"Using Gemini model: {GEMINI_MODEL} via Vertex AI")
        logger.info(f"Project: {GCP_PROJECT_ID}, Location: {GCP_LOCATION}")
        
        self.running = True
        # Start message processing task
        self.process_task = asyncio.create_task(self.process_messages())
        
        logger.info(f"Agent {self.name} started successfully")
        return True
        
    async def stop(self):
        """Stop the agent"""
        logger.info(f"Stopping agent {self.name}")
        self.running = False
        
        # Wait for the processing task to complete
        if hasattr(self, 'process_task'):
            self.process_task.cancel()
            try:
                await self.process_task
            except asyncio.CancelledError:
                pass
            
        logger.info(f"Agent {self.name} stopped")
        
    def is_alive(self):
        """Check if the agent is running"""
        return self.running 